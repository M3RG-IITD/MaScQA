We can use Bragg's Law to solve this problem, which states:

n λ = 2 d sin(θ)

where n is the order of the reflection (n = 1 for the first-order reflection), λ is the wavelength of the X-rays, d is the spacing between the crystal planes, and θ is the Bragg angle.

For a face-centered cubic (FCC) crystal, the spacing between (111) planes can be calculated as:

d = a / sqrt(3)

where a is the lattice parameter.

Substituting this expression and the given values into Bragg's Law, we get:

λ = 2 d sin(θ) / n = 2 a sin(θ) / (n sqrt(3))

Plugging in the values given in the problem, we get:

λ = 2×0.3615 nm × sin(21.68°) / 1 / sqrt(3) = 0.154 nm

Therefore, the wavelength of X-rays is 0.154 nm.

Answer: [0.154]